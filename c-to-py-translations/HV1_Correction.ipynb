{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db605535-146b-4854-a72d-3b6f71d7b32a",
   "metadata": {},
   "source": [
    "# HV Calibration\n",
    "\n",
    "This notebook is a first attempt at performing correction based on HV data. The calibration will be based on Matt's work [here (login required)](https://zzz.physics.umn.edu/!cdms/cdms/k100/run_summary/run_76#calibration_with_baseline_correction), rather than the previous, incorrect ladder calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516a6efc-3974-4989-ae19-8fe92a3de968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stard\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lmfit as lf\n",
    "import matplotlib.pyplot as plt\n",
    "from R76Tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba4a12-a973-4ab0-95d3-1d2d22198fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"R76Data/\"\n",
    "ser = [\"07220822_1828\",\"07220826_1219\",\"07220826_1536\",\"07220826_2007\",\"07220827_1153\",\"07220830_1724\"]#[\"07220702_0911\"]\n",
    "lab = [\"0V\",\"-4V\",\"-21V\",\"-65V\",\"-84V\",\"-84V\"] #[\"data\"]\n",
    "online = False #leave this off if you can; online mode takes much longer\n",
    "\n",
    "nser = len(ser); e=[]; z=[];\n",
    "for s in range(nser):\n",
    "    if not online:\n",
    "        filelist = glob.glob(datapath+ser[s]+\"/umn*.root\")\n",
    "        e_chain,z_chain = makechain(filelist,fittingfilters)\n",
    "    else:\n",
    "        e_chain,z_chain = makeonlinechain(ser[s],user=\"harrisk\",filters=fittingfilters)\n",
    "    e.append(e_chain); z.append(z_chain)\n",
    "    \n",
    "for i,x in enumerate(z):\n",
    "    z[i] = pd.concat([x,e[i]],axis=1)\n",
    "\n",
    "if(not online and len(z[0]) == 0):\n",
    "    raise ValueError(\"No data loaded for at least one dataset! Do you have all the data files?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30533af5-95b9-48e2-be9d-2732f6b36ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mman = -0.232; bman = 150\n",
    "for x in z:\n",
    "    x['crand'] = crand(x)\n",
    "    x['PTwid'] = PTwid(x)\n",
    "    x['PTdbs'] = PTdbs(x)\n",
    "    x['pt_keV'] = pt_keV(x)\n",
    "    x['cam'] =  cam(x)\n",
    "    x['cphi1'] = cphi1(x)# [(y>5) and (y<20) for y in phidel(x)]\n",
    "    x['PSUMbs'] = PSUMbs(x)\n",
    "    x['pt_keV_bscorr'] = x['pt_keV']/(1.+mman*(x['PSUMbs']-18000.)/bman) #baseline correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f4999a-d3c9-4b30-a54d-7dfa42e1c71d",
   "metadata": {},
   "source": [
    "To get the aliases right, trying to reproduce: https://zzz.physics.umn.edu/!cdms/cdms/k100/run_summary/run_76#calibration_with_baseline_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a5d12-b20a-4947-99c3-303bb780881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "#Going to apply several data cuts in order to narrow down where we can fit to\n",
    "\n",
    "h = plt.hist2d(z[4][\"PSUMbs\"][~z[4][\"crand\"] & z[4][\"cam\"] & z[4][\"cphi1\"]]-18000,\n",
    "               z[4][\"pt_keV\"][~z[4][\"crand\"] & z[4][\"cam\"] & z[4][\"cphi1\"]]\n",
    "              ,bins=[np.linspace(-50,2500,200),np.linspace(50,200,150)])\n",
    "plt.ylabel(\"Phonon energy [keV]\")\n",
    "plt.xlabel(\"Baseline elevation\") \n",
    "\n",
    "fig.colorbar(h[3])\n",
    "x = np.array([0,300])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e25806a9-0984-4859-9a6d-d0b5f4d8b1ef",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "h = plt.hist2d(z[4][\"PSUMbs\"][~z[4][\"crand\"] & z[4][\"cam\"]]-18000,z[4][\"pt_keV_bscorr\"][~z[4][\"crand\"] & z[4][\"cam\"]]\n",
    "               ,bins=[np.linspace(-50,2500,200),np.linspace(50,200,150)])\n",
    "plt.ylabel(\"Baseline-corrected phonon energy [keV]\")\n",
    "plt.xlabel(\"Baseline elevation\") #Not true yet; just the goal. \n",
    "#Based on the calculation I think this might be what I have now? But,\n",
    "#Based on the plot it's very clearly not it.\n",
    "fig.colorbar(h[3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba932534-3ff7-4278-9cb7-08b087bd7500",
   "metadata": {},
   "source": [
    "# An Automatic Fit\n",
    "\n",
    "Below we will attempt to get this baseline correction automatically by fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b49ef-35a6-4da9-ad0e-fb650e0f6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.sqrt(h[0]) #Get errors -- still sqrt(n)\n",
    "\n",
    "def f(x,m=mman,b=bman): #function for a line\n",
    "    return m*x+b\n",
    "\n",
    "#No reason I can't do this as a scatter plot, right? will be easier to fit if I treat it that way.\n",
    "plt.scatter(z[4][\"PSUMbs\"][~z[4][\"crand\"]][z[4][\"cphi1\"]][z[4][\"cam\"]]-18000,z[4][\"pt_keV\"][~z[4][\"crand\"]][z[4][\"cphi1\"]][z[4][\"cam\"]],s=0.1)\n",
    "plt.xlim(-50,400)\n",
    "plt.ylim(0,300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb46e7-5be5-4934-a3f1-cf31f040c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic fit -- I expect issues with this due to many data points being the wrong region.\n",
    "\n",
    "x = z[4][\"PSUMbs\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"] & (z[4][\"pt_keV\"]>50)]-18000\n",
    "y = z[4][\"pt_keV\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"] & (z[4][\"pt_keV\"]>50)] #cutting out all the \"noise\" at the bottom.\n",
    "#y=y[(x>0) & (x<200)];x = x[(x>0) & (x<200)] #cut off both at the end of the line\n",
    "\n",
    "mod = lf.Model(f)\n",
    "params = mod.make_params()\n",
    "params.add('m',value=-0.232,max=0,min=-1); params.add('b',value=150,min=0,max=1000)\n",
    "fit = mod.fit(y,params,x=x,method='basinhop') #might be the best method for this data? not seeing singificant differences anymore\n",
    "#Is this okay? It's fitting to the wrong y-intercept but all I want is the slope...\n",
    "\n",
    "plt.scatter(z[4][\"PSUMbs\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"]]-18000,z[4][\"pt_keV\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"]],s=0.05,color='r',label='Unfitted data')\n",
    "plt.scatter(x,y,s=0.1,label='Fitted data')\n",
    "\n",
    "plt.plot(x,fit.best_fit,linestyle='--',color='k',linewidth=1,label=\"Auto fit\")\n",
    "#plt.plot(x,fit.best_fit+15,linestyle='--',color='r',linewidth=1,label=\"Auto fit height-adjust\")\n",
    "#plt.plot(x,f(x,m=mman,b=bman),color='b',linewidth=0.5,label=\"Manual fit\")\n",
    "\n",
    "plt.xlim(-50,400)\n",
    "plt.ylim(0,300)#,200)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe4e9d-59b4-4812-83ef-a16982fe7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist2d(z[4][\"PSUMbs\"][~z[4][\"crand\"]]-18000,z[4][\"pt_keV\"][~z[4][\"crand\"]]\n",
    "               ,bins=[np.linspace(-50,400,200),np.linspace(0,300,150)])\n",
    "\n",
    "plt.plot(x,fit.best_fit,linestyle='--',color='k',linewidth=1,label=\"Auto fit\")\n",
    "#plt.plot(x,fit.best_fit+15,linestyle='--',color='r',linewidth=1,label=\"Auto fit height-adjust\")\n",
    "#plt.plot(x,f(x,m=mman,b=bman),color='b',linewidth=0.5,label=\"Manual fit\")\n",
    "\n",
    "plt.xlim(-50,400)\n",
    "plt.ylim(0,300)#,200)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d378db0-93d0-49a9-8e69-7038388cea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in z:\n",
    "    x['new_bscorr'] = x['pt_keV']/(1.+fit.best_values['m']*(x['PSUMbs']-18000.)/fit.best_values['b']) #baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a2989-b58a-4583-9b76-8a14f5828b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(15,6),constrained_layout=True,sharey=True)\n",
    "#ax = axs[0]; ax2 = axs[1]; ax3 = axs[2]\n",
    "ax2 = axs[0]; ax3 = axs[1]\n",
    "#h = ax.hist2d(z[4][\"PSUMbs\"][~z[4][\"crand\"]]-18000,z[4][\"pt_keV_bscorr\"][~z[4][\"crand\"]]\n",
    "#               ,bins=[np.linspace(-50,400,200),np.linspace(0,300,150)])\n",
    "ax2.set_ylabel(\"Baseline-corrected phonon energy [keV]\",weight='bold',fontsize=12)\n",
    "#ax2 = fig.add_subplot(1,3,2)\n",
    "h = ax2.hist2d(z[4][\"PSUMbs\"][~z[4][\"crand\"]]-18000,z[4][\"new_bscorr\"][~z[4][\"crand\"]]\n",
    "               ,bins=[np.linspace(-50,400,200),np.linspace(0,300,150)])\n",
    "#ax3 = fig.add_subplot(1,3,3)\n",
    "h = ax3.hist2d(z[4][\"PSUMbs\"][~z[4][\"crand\"]]-18000,z[4][\"pt_keV\"][~z[4][\"crand\"]]\n",
    "               ,bins=[np.linspace(-50,400,200),np.linspace(0,300,150)])\n",
    "ax2.set_xlabel(\"Baseline\",weight='bold',fontsize=12)\n",
    "#Based on the calculation I think this might be what I have now? But,\n",
    "#Based on the plot it's very clearly not it.\n",
    "fig.colorbar(h[3])\n",
    "\n",
    "#ax.set_title(\"Manual\",weight='bold',size=16)\n",
    "ax2.set_title(\"Automatic\",weight='bold',size=16)\n",
    "ax3.set_title(\"Uncorrected\",weight='bold',size=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1fd77a-55b1-4741-b327-e6d745256dc2",
   "metadata": {},
   "source": [
    "# Current Ideas\n",
    "\n",
    "* More cuts? Don't have any idea how to do more cuts.\n",
    "* Different fitting method? I have tried those provided by lmfit and this gives the best results\n",
    "* Further constraints on parameters? I don't want to over-constrain the parameters because this needs to be robust enough to work on a new data set.\n",
    "* Set y-intercept first? Not sure how to do this but it may help get a better slope.\n",
    "\n",
    "Let's experiment with the y-intercept idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac4de9e-598e-49f7-bece-de082cca80fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(24,9))\n",
    "\n",
    "def gaussian(x,mu,sigma):\n",
    "    return 1/np.sqrt(2*np.pi*sigma**2)*np.exp(-(x-mu)**2)\n",
    "mod = lf.Model(gaussian)\n",
    "params = mod.make_params()\n",
    "params.add('mu',value=150); params.add('sigma',value=5)\n",
    "\n",
    "x = z[4][\"PSUMbs\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"] & (z[4][\"pt_keV\"]>50)]-18000\n",
    "y = z[4][\"pt_keV\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"]  & (z[4][\"pt_keV\"]>50)] #cutting out all the \"noise\" at the bottom.\n",
    "\n",
    "bins = np.linspace(120,180,30)\n",
    "h0 = ax[0].hist(y[(x<20) & (x>0)],bins=bins); h0y = h0[0]; h0x = h0[1]\n",
    "h0x = (h0x[:-1] + h0x[1:])/2\n",
    "fit1l = mod.fit(h0y[(h0x<155) & (h0x>140)],params,x=h0x[(h0x<155) & (h0x>140)])\n",
    "fit1r = mod.fit(h0y[h0x>150],params,x=h0x[h0x>150])\n",
    "ax[0].plot(h0x[(h0x<155) & (h0x>140)],fit1l.best_fit); ax[1].plot(h0x[h0x>150],fit1r.best_fit)\n",
    "\n",
    "bins = np.linspace(120,170,30)\n",
    "low = 20; high = 40\n",
    "h1 = ax[1].hist(y[(x<high) & (x>low)],bins=bins); h1y = h1[0]; h1x = h1[1]\n",
    "h1x = (h1x[:-1] + h1x[1:])/2\n",
    "fit2l = mod.fit(h1y[(h1x<150) & (h1x>135)],params,x=h1x[(h1x<150) & (h1x>135)])\n",
    "fit2r = mod.fit(h1y[h1x>150],params,x=h1x[h1x>150])\n",
    "ax[1].plot(h1x[(h1x<150) & (h1x>135)],fit2l.best_fit); ax[1].plot(h1x[h1x>150],fit2r.best_fit)\n",
    "#ax[1].axvline(np.mean(y[(x<high) & (x>low)]),color='k')\n",
    "#ax[1].axvline(fit.best_values['b'],color='k',linestyle='--')\n",
    "\n",
    "bins = np.linspace(120,170,30)\n",
    "low = 40; high = 60\n",
    "h2 = ax[2].hist(y[(x<high) & (x>low)],bins=bins); h2y = h2[0]; h2x = h2[1]\n",
    "h2x = (h2x[:-1] + h2x[1:])/2\n",
    "fit3l = mod.fit(h2y[(h2x<145) & (h1x>135)],params,x=h2x[(h2x<145) & (h2x>135)])\n",
    "fit3r = mod.fit(h2y[h2x>145],params,x=h2x[h2x>145])\n",
    "ax[2].plot(h2x[(h2x<150) & (h2x>135)],fit2l.best_fit); ax[1].plot(h2x[h2x>150],fit2r.best_fit)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c1569b-8004-4801-a695-37e4ca915db7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = z[4][\"PSUMbs\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"] & (z[4][\"pt_keV\"]>50)]-18000\n",
    "y = z[4][\"pt_keV\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"]  & (z[4][\"pt_keV\"]>50)] #cutting out all the \"noise\" at the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e93c96-fecc-47b6-906b-84c13c7e6b9d",
   "metadata": {},
   "source": [
    "So it seems like it *is* actually choosing the mean for the intercept, roughly? It's being pulled slightly downward. What if I set the mean as the minimum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8941a10b-926c-41fb-b898-1799c242b34a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Basic fit -- I expect issues with this due to many data points being the wrong region.\n",
    "\n",
    "x = z[4][\"PSUMbs\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"] & (z[4][\"pt_keV\"]>50)]-18000\n",
    "y = z[4][\"pt_keV\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"]  & (z[4][\"pt_keV\"]>50)] #cutting out all the \"noise\" at the bottom.\n",
    "#y=y[(x>0) & (x<200)];x = x[(x>0) & (x<200)] #cut off both at the end of the line\n",
    "\n",
    "mod = lf.Model(f)\n",
    "params = mod.make_params()\n",
    "params.add('m',value=-0.232,max=0,min=-1); params.add('b',value=150,min=np.mean(y[(x<5) & (y>-5)]),max=1000)\n",
    "fit = mod.fit(y,params,x=x,method='basinhop') #might be the best method for this data? not seeing singificant differences anymore\n",
    "#Is this okay? It's fitting to the wrong y-intercept but all I want is the slope...\n",
    "\n",
    "plt.scatter(z[4][\"PSUMbs\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"]]-18000,z[4][\"pt_keV\"][~z[4][\"crand\"] & z[4][\"cphi1\"] & z[4][\"cam\"]],s=0.05,color='r',label='Unfitted data')\n",
    "plt.scatter(x,y,s=0.1,label='Fitted data')\n",
    "\n",
    "plt.plot(x,fit.best_fit,linestyle='--',color='k',linewidth=1,label=\"Auto fit\")\n",
    "plt.plot(x,fit.best_fit+15,linestyle='--',color='r',linewidth=1,label=\"Auto fit height-adjust\")\n",
    "plt.plot(x,f(x,m=mman,b=bman),color='b',linewidth=0.5,label=\"Manual fit\")\n",
    "\n",
    "plt.xlim(-50,400)\n",
    "plt.ylim(0,300)#,200)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5faada7-36ce-449f-a437-01e1586a32cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(20,6),constrained_layout=True,sharey=True)\n",
    "ax = axs[0]; ax2 = axs[1]; ax3 = axs[2]\n",
    "h = ax.hist2d(z[4][\"PSUMbs\"][~z[4][\"crand\"]]-18000,z[4][\"pt_keV_bscorr\"][~z[4][\"crand\"]]\n",
    "               ,bins=[np.linspace(-50,400,200),np.linspace(0,300,150)])\n",
    "ax.set_ylabel(\"Baseline-corrected phonon energy [keV]\",weight='bold',fontsize=12)\n",
    "#ax2 = fig.add_subplot(1,3,2)\n",
    "h = ax2.hist2d(z[4][\"PSUMbs\"][~z[4][\"crand\"]]-18000,z[4][\"new_bscorr\"][~z[4][\"crand\"]]\n",
    "               ,bins=[np.linspace(-50,400,200),np.linspace(0,300,150)])\n",
    "#ax3 = fig.add_subplot(1,3,3)\n",
    "h = ax3.hist2d(z[4][\"PSUMbs\"][~z[4][\"crand\"]]-18000,z[4][\"pt_keV\"][~z[4][\"crand\"]]\n",
    "               ,bins=[np.linspace(-50,400,200),np.linspace(0,300,150)])\n",
    "ax2.set_xlabel(\"Baseline\",weight='bold',fontsize=12)\n",
    "#Based on the calculation I think this might be what I have now? But,\n",
    "#Based on the plot it's very clearly not it.\n",
    "fig.colorbar(h[3])\n",
    "\n",
    "ax.set_title(\"Manual\",weight='bold',size=16)\n",
    "ax2.set_title(\"Automatic\",weight='bold',size=16)\n",
    "ax3.set_title(\"Uncorrected\",weight='bold',size=16)\n",
    "\n",
    "comment = \"\"\"\n",
    "pointsx = [0,0.22e-6,0.29e-6,0.38e-6] #Measured outputs, not yet known.\n",
    "\n",
    "plt.axhline(pointsx[1],color='red',linestyle='dotted')\n",
    "plt.axhline(pointsx[2],color='red',linestyle='dotted')\n",
    "plt.axhline(pointsx[3],color='red',linestyle='dotted')#\"\"\"\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfc54c5-1add-4589-9ca2-de04727ada52",
   "metadata": {},
   "source": [
    "The intercept is more correct, but the slope, which we actually care about, is worse. Is there some way we can use this kind of method to remove noise?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
